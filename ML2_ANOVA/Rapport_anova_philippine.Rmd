---
title: "ML2 TP ANOVA"
output:
  word_document: default
  html_document:
    df_print: paged
---
```{r message=FALSE, warning=FALSE}
library(lmtest)
library(car)
```

# Exercice 2: ANOVA à un facteur

Le fichier "chemical.txt"  contient les observations de concentration chimique dans le sang  __conc__ (en ng/ml) pour un groupe de 10 patients après administration orale de 4 doses dfférentes __dose__ (25,50,100,200 mg) d'un médicament (almitrine bismesylate). On veut étudier l'influence du traitement sur les caractéristiques chimiques du sang.

```{r}
data=data.frame(read.csv("C:/Users/Philippine/Documents/Cours/Maths/M1/S2/Data_Mining/chemical.txt", sep=" ", h=F, skip=1, col.names = c("index","conc","dose")))[,2:3]
data
Y=data$conc
X=as.factor(data$dose)
```

1. Représenter les données à l'aide de boîtes à moustaches. Commenter. Les hypothèses d'une analyse de variance semble-t'elle vérifées ?

```{r}
stripchart(Y~X, xlab="concentration", ylab="dose")
moy=by(Y,X,mean);moy
boxplot(Y~X, xlab="dose")
points(1:4,moy,col='red',pch=20)
```

__Commentaire__ : Les diagrammes en boite montrent des différences de moyenne (points rouges) entre les différentes modalités du facteur __dose__. De plus, la répartition des concentration en fonction des modalités est très différente: la modalité 100mg est celle qui connait les plus grands écarts de concentration mais aussi les mieux répartis. Les patients doivent réagir très différemment les uns des autres quand on leur administre une dose de 100mg de produit. En revanche, lorsque l'on administre une dose de 25mg ou de 50mg, les patients semblent réagir de manière plus homogène. Enfin, la dernière modalité possède la plus forte moyenne et un outlier ayant une forte valeur de concentration. Est-ce une erreur de mesure ou a-t-on à faire à un patient très atypique ? Influence-t-t-il beaucoup la moyenne de cette modalité ? Il faudrait évaluer si cette individu est vraiment considéré comme outlier (distance de cook). Il en va de même pour la modalité 50mg.


Pour réaliser une analyse de variance (à un facteur), il faut que la variable cible Y soit quantitative et que la variable explicative soit un facteur à q modalités.

De plus, pour une analayse de variance, on s'appui sur l'hypothèse de linéarité et de normalité du modèle.
Il faut donc vérifier que les résidus du modèle Yik=yik+eik soit gaussiens, centrés, de même variance et indépendants.

Dans cette étude, nous avons bien Y (conc) quantitative et la variable __dose__ est un facteur à 4 modalités (25,50,100,200).Nous vérifions dans la deuxième question les hypothèses citées.


2. On cherche à vérifier si l'hypothèse d'homoscédasticité des modalités a lieu. Pour cela, effectuer le test de Bartlett.

```{r}
mod1=aov(Y~X)
res1=mod1$residuals
shapiro.test(res1) #test de normalité des résidus
dwtest(mod1)       #test d'indépendance des résidus
bartlett.test(res1~X) #test homoscédasticité des résidus
```

Le test de Bartlett nous indique une non homoscédasticité des résidus: les résidus n'ont pas tous même variance. L'hypothèse d'homoscédasticité n'est donc pas vérifiée avec ce modèle.
(On voit aussi que l'hypothèse de normalité est rejetée mais que celle d'indépendance ne l'est pas).


3. Pour éviter ce phénomène, on propose de s'intéresser à une transformation logarithmique de la variable __conc__ (Y) . Représenter les boîtes à moustaches des données transformées. Vérifier la procédure de stabilisation avec le test de Bartlett sur __log(Y)__  ainsi que la normalité.

```{r}
moy_log=by(log(Y),X,mean);moy_log
boxplot(log(Y)~X, xlab="dose")
points(1:4,moy_log,col='red',pch=20)
mod2=aov(log(Y)~X)
res2=mod2$residuals
bartlett.test(res2~X)
shapiro.test(res2)
```

Les nouveaux diagrammes permettent d'avoir une meilleure vision de la répartition des concentrations mesurées en fonction de la dose administrée. Les diagrammes des 2 premières modalités montrent une répartition plus ou moins homogène de la concetration autour de la médiane de la modalité. On remarque toujours une différence de moyenne entre chaque modalité (même si la présence d'un outlier influence peut-être encore la moyenne de la modalité et que celle-ci ne soit en faite pas si différente de la moyenne de la modalité 100) .

On a maintenant homoscédasticité des résidus grâce au changement logarithmique effectué sur Y.
On a également la normalité des résidus. Ce nouveau modèle répond donc aux hypoyhèses de l'analyse de variance, c'est à dire la normalité, l'homoscédasticité et l'indépendance des résidus. (On les suppose centrés par construction)


4. Réaliser l'analyse de variance (phase d'estimation). Retouver manuellement les résultats en construisant la matrice 'Xind' adaptée.

```{r}
mod2$coefficients 
y1=mod2$coefficients[1];y1 # moyenne de la modalité 1
y2=mod2$coefficients[2]+y1;y2 # moyenne de la modalité 2
y3=mod2$coefficients[3]+y1;y3 # moyenne de la modalité 3
y4=mod2$coefficients[4]+y1;y4 # moyenne de la modalité 4
y_bar=(y1+y2+y3+y4)/4;y_bar # moyenne générale
anova(mod2) #on trouve SCM = 22.9380
            # SCR=3.6837
            # SCM=22.9380
            # sigma2_est=0.1023
            # F=74.723
            # p-val=1.575e-15

Xind=as.matrix(data.frame(model.matrix(~X-1))); Xind

#Estimation des paramètres à la main (on utilise log(Y))
Beta_chap=solve(t(Xind)%*%Xind)%*%t(Xind)%*%log(Y);Beta_chap #donne les valeur des moyennes par modalité
Yc=Xind%*%Beta_chap      #Y chapeau
SCR=sum((log(Y)-Yc)**2);SCR
sigma_est=SCR/36;sigma_est
SCM=sum((Yc-mean(log(Y)))**2);SCM
testF=(SCM/3)/(SCR/36);testF
p_val=1-pf(testF,3,36);p_val  # 3 = nb de modalité -1
                              # 36 = dimension de Y - nombre de modalité de X
```


5. Construire le tableau d'analyse de variance et interpréter les résultats. Conclure quant à l'effet du traitement.

On va construire à la main le tableau que nous donne la commande anova(mod2)

```{r}
tableau_anova=data.frame(Source=c("X","Residuals"),Df=c(3,36),Sum_Sq=c(22.938,3.684),Mean_Sq=c(7.646,0.102),F_value=c(74.72,"NA"),pval=c(1.58e-15,"NA")); tableau_anova
```

__Interprétation__ : La p-value du test de Fisher nous conduit à rejeter l'hypothèse nulle d'égalité des moyennes entre modalité (On a une grande valeur de SCM et une petite valeur de SCR, cela était donc prévisible). La dose de médicament injectée a donc vraisemblablement une influence sur la concentration dans le sang car les moyennes sont significativement différentes.


6. On veut à présent comparer plus précisemment les effets de la dose sur la concentration selon la quantité de médicament prescrite. Interpréter les résultats de coef(mod2) puis ceux de coef(mod3) où mod3=lm(concent~-1+dose). Comparer deux à deux les effets selon la dose, à l'aide de la méthode de Bonferroni puis de la méthode de Tukey.

```{r}
coef(mod2)
mod3=lm(log(Y)~-1+X);coef(mod3)
LSD_Bonf=qt(1-(0.05/6)/2,36)*sqrt(8*sigma_est/40);LSD_Bonf
pairwise.t.test(log(Y),X,p.adj="bonf")
LSD_Tukey=qtukey(0.95,4,36)*sqrt(4*sigma_est/40);LSD_Tukey
TukeyHSD(aov(mod2),'X')
plot(TukeyHSD(mod2,'X'))
```

Les coefficients affichés par la commande coef(mod2) représentent les moyennes des modalités, en prenant la première modalité comme modalité de référence. On a donc, comme vu précédemment, y1=3.615, y2=4.622, y3=5.253, y4=5.609. Les Yik sont donc égaux à yik+eik. Les valeurs observées de la concentration en fonction de la dose de médicament prescrite peuvent donc être considérées comme étant égales à la moyenne des valeurs de concentration observée pour cette modalité + un terme d'erreur gaussien.

Ce 3ème modèle (mod3) correspond à ce que l'on fait à la main, les coefficients ici sont directement les moyennes de chaque modalité. On retrouve d'ailleurs les mêmes résultats. (Ouf!)

Avec la méthode de Bonferroni, 2 moyennes sont significativement différentes si elles diffèrent de plus de 0,399. on a donc y1!=y2,y3,y4; y2!=y1,y3,y4 et y3!=y1,y2 mais y3 et y4 sont significativement égales.(Ce qu'on peut voir plus facilement grâce à la commande pairwise)

Avec la méthode de Tukey, 2 moyennes sont significativement différentes si elles diffèrent de plus de 0,385. On voit donc grâce à la commande plot(TukeyHSD(mod2,'X')) que là aussi y3 et y4 ne sont pas significativement différentes. Il semblerait donc que les différentes doses aient une influence particulière sur la concentration mais que les doses 100mg et 200mg aient le même effet (si l'on se fie à ces indicateurs)


7. Tester avec la méthode de Tukey une différence significative entre une dose de 25mg et 50mg .

On a vu à la question précédente que LSD_Tukey donne une p-val de 1.7e-07 pour l'hypothèse nulle "y1=y2" donc y1 et y2 ne sont pas significativement égales. Il y a une différence significative entre y1 et y2, c'est à dire entre une dose de 25mg et une dose de 50mg.


8. On veut tester à l'aide de la méthode des contrastes l'égalité de la différence des effets entre 25mg et 50mg et entre 50mg et 100mg . On utilise alors la fonction lht de la library car.
Même question entre 25mg et 50mg et entre 200mg et 100mg.

```{r}
library(car)
lht(mod3,c(1,-2,1,0))
lht(mod3,c(1,-1,1,-1))

lht(mod2,c(0,2,-1,0)) #on retrouve bien les mêmes résultats, que ce soit avec X ou X-1
lht(mod2,c(0,1,-1,1))
```

La p-value du 1er test nous conduit à ne pas rejeter l'hypothèse nulle H0:"y1-y2=y2-y3". Cela signifie que les différences d'effet entre 25mg et 50mg et 50mg et 100mg sont significatvement égales.

La p-value du 2ème test nous conduit cette fois-ci à rejeter l'hypothèse nulle H0:"y1-y2=y4-y3". Cela signifie que les différences d'effet entre 25mg et 50mg et 100mg et 200mg sont significativement différentes.
Ces résultats sont assez logiques car nous avons mis en avant dans les questions prédédentes que y1, y2 et y3 étaient significativement différentes entre elles mais que y3 et y4 ne pouvaient pas être considérées comme significativement différentes. L'effet entre 100mg et 200mg est donc très faible comparé à celui entre 25mg et 50mg.



#Exercice 3: ANOVA à deux facteurs

1. Déterminer les moyennes des modalités et des interactions et représenter graphiquement les effets moyens et les interactions. Quelles sont les conjectures envisageables quant aux résultats de l'analyse?

```{r}
data(warpbreaks)
donnees=warpbreaks
model=lm(breaks~wool+tension + wool:tension, data=donnees)
moy_wool=by(donnees$breaks,donnees$wool,mean);moy_wool
moy_tension=by(donnees$breaks,donnees$tension,mean);moy_tension
by(donnees$breaks,list(donnees$wool,donnees$tension),mean)
boxplot(donnees$breaks~donnees$wool)
points(1:2,moy_wool,col='red',pch=20)
boxplot(donnees$breaks~donnees$tension)
points(1:3,moy_tension,col='red',pch=20)
interaction.plot(donnees$tension,donnees$wool,donnees$breaks)
```

__Interprétation__: La moyenne pour la modalité A de Wool est 31.04 et celle pour la modalité B est 25.26. On voit également grâce au boxplot que ces moyennes sont assez proches et que les valeurs de breaks sont plus étendues pour la modalité A que pour la modalité B. On note la présence de 2 outliers pour la modalité A qui augmentent certainement la moyenne de la moyenne de la modalité A. Graphiquement parlant (et en supprimant les 2 points outliers), on aurait donc tendance à dire que le facteur __wool__ seul n'a pas d'effet significatif sur la variable __breaks__ (en terme de différence de moyenne : SCM faible, en terme de dispersion des données et SCR fort, ce qui implique un non rejet de l'hypothèse nulle d'égalité des moyennes).

Les moyennes pour les modalités L,M et H du facteur __tension__ sont respectivement 36.39, 26.39, 21.67. Les diagrammes en boite mettent en évidence des écarts de moyenne entre les 3 modalités. La répartition des valeurs de breaks pour les modalités M et H semble être homogène autour de la moyenne/médiane alors que c'est beaucoup plus hétérogène pour la modalité L. De plus, les écarts entre moyennes ont l'air assez faibles entre les modalités M et H, donc on pourrait penser que même s'il y a des écarts de moyennes, la répartition très hétérogène des valeurs de breaks pour chaque modalité donne un SCR élevé. On se retrouve donc comme dans le cas précédent avec un SCM faible et un SCR fort donc une statistique de test F faible et donc un rejet de l'hypothèse nulle.

Cependant, toutes ces conjectures sont purement graphique, on ne peut donc en réalité rien conclure quant à l'effet réel de chacun des facteurs sur la variable __breaks__. Si l'on se base sur les différences de moyennes uniquement, on aurait tendance à dire que le facteur __tension__ a plus d'influence que le facteur __wool__.

Les moyennes pour les modalités des deux facteurs combinés sont : 
yAL=44.56, yBL=28.22, yAM=24, yBM=28.78, yAH=24.56 et yBH=18.78. Le plot des interactions montre des interactions entre les modalités des deux facteurs. Pour la modalité L de __tension__ il y a des fortes différences de moyennes entre les 2 modalités de __wool__. On note de même des interactions plus faible pour les modalités H et M.
Ce graphique nous indique donc qu'il y a des interactions entre les deux facteurs et donc que même si individuellement, les facteurs semblent n'avoir aucun effet, ils peuvent avoir un effet à travers leurs interactions.


2. Vérifier les hypothèses du modèle gaussien. Conclure.

```{r}
residus=model$residuals
shapiro.test(residus)
bartlett.test(residus,donnees$wool)
bartlett.test(residus,donnees$tension)
bartlett.test(residus,donnees$wool:donnees$tension)
dwtest(model)
```

On remarque que ce modèle vérifie bien les hypothèses de normalité et d'indépendance des résidus mais pour l'hypothèse d'homoscédasticité cela est plus ambigu au risque 5% (on rejetterait l'hypothèse d'homoscédasticité ici). Regardons ce qu'il se passe si l'on considère log(breaks).


3. On propose le changement de variable lbreaks=log(breaks). Reprendre la question précédente.

```{r}
model2=lm(log(breaks)~wool+tension + wool:tension, data=donnees)
residus2=model2$residuals
shapiro.test(residus2)
bartlett.test(residus2,donnees$wool)
bartlett.test(residus2,donnees$tension)
bartlett.test(residus2,donnees$wool:donnees$tension)
dwtest(model2)
```

On a maintenant vérification de tous les postulats d'un modèle linéaire. On va donc pouvoir faire une analyse de variance à deux facteurs (en prenant en compte les interactions).


4. Interpréter l'analyse de variance de votre modèle: Expliquez pourquoi la présence d'interactions fortes compliquent l'interprétation des effets des facteurs.

```{r}
anova(model2)
```

__Interprétation__ : 
Cette anova nous montre qu'au risque 5% on doit rejeter l'hypothèse nulle de la nullité des coefficients d'interactions entre les deux facteurs (même si la p-value est très ambigue au risque 5%). Il semble donc y avoir des interactions significatives entre les facteurs ayant donc un effet sur la variable __breaks__.

Si l'on considérait un risque 1%, on ne rejetterait pas l'hypothèse nulle et donc on interpréterait les effets des facteurs (individuellement) de la manière suivante:

1. La p-value du facteur __wool__ est supérieure à 0.01 donc on ne rejette pas l'hypothèse nulle de nullité du coefficient d'effet principal du facteur __wool__. En des termes plus clairs, le facteur __wool__ n'a significativement pas d'effet sur la variable __breaks__.

2. A l'inverse du facteur __wool__, la p-value du facteur __tension__ (0.0012) indique qu'il faut rejeter l'hypothèse nulle. Le facteur __tension__ a donc un effet significatif sur la variable __breaks__.

Or, comme nous considérons un risque 5% ici, on ne peut plus du tout conclure la même chose. Comme il existe des interactions significatives entre les deux facteurs, les effets principaux (affichés ici) de chaque facteur en sont affectés et donc les résultats que nous avons ici sont ininterprétables. 
Pour pouvoir interpréter et quantifier les effets principaux des facteurs, il faudrait réaliser une anova à un facteur (tension par exemple) pour chaque modalité de wool fixée.


5. Le facteur __wool__ présente une influence à travers son interaction avec le facteur __tension__. Comparer le modèle complet avec interaction avec le modèle sans le facteur __wool__ en utilisant la commande "anova(mod1,mod2)". Que fait anova(mod1,mod2)?

```{r}
model3=lm(log(breaks)~tension, data=donnees)
anova(model2,model3)
```

La commande anova(model2,model3) permet de comparer les deux modèles en terme de qualité explicative (modélisation) des données. Cette commande permet de tester H0:"Le modèle 1 est meilleur que le modèle 2" vs H1:"Le modèle 2 est meilleur que le modèle 1".

Ici, au risque 5% la p-value est une fois de plus ambigue. Si l'on suit strictement la règle de décision alors on rejette l'hypothèse nulle, le modèle sans le facteur __wool__ semble "meilleur" ou du moins explique au moins autant les données que le modèle complet. Il semblerait donc que même si le facteur __wool__ a un effet sur __breaks__ à travers son interaction avec le facteur __tension__, si ce facteur est exclus de l'analyse, cela ne change pas grand chose.

Si l'on se place au risque 1%, dans ce cas, on ne rejette pas l'hypoyhèse nulle et le facteur __wool__ apporte bel et bien de l'information.


6. Comparer les modalités de __wool__ puis __tension__ deux à deux avec le test de Tukey. Les représenter graphiquement. Pourquoi ces compraisons ne sont pas pertinentes voir erronées ici?

```{r}
TukeyHSD(aov(model2),'wool')
plot(TukeyHSD(aov(model2),'wool'))
TukeyHSD(aov(model2),'tension')
plot(TukeyHSD(aov(model2),'tension'))
```

On voit ici que pour le facteur __wool__, on ne rejette pas H0 (au risque 5%), donc les moyennes des deux modalités ne sont pas significativement différentes. Le facteur __wool__ n'a pas d'effet sur la variable __breaks__.

Pour le facteur __tension__, seules les modalités H et L présentent une différence significative de moyenne (au risque 5%). Les moyennes des modalités M et L et des modalités H et M sont significativement (et respectivement) égales d'après cet indicateur.

Or, ces comparaisons ne sont pertinentes que dans le cas où l'on a pas rejettée l'hypothèse de nullité des coefficients d'interaction entre facteurs. Or précédemment, nous avons rejeté au risque 5% cette hypothèse. Il y a donc des interactions entre les 2 facteurs et on ne peut plus interpréter et quantifier les effets principaux de chaque facteur de cette manière.


7. Comparer les interactions deux à deux.

```{r}
TukeyHSD(aov(model2),'wool:tension')
plot(TukeyHSD(aov(model2),'wool:tension'))
```

Si l'on compare 2 à 2 les interactions, on se rend compte que pour la modalité A de __wool__ il y a une différence de moyenne significative pour les modalités M et L de __tension__, pareil pour les modalités H et L. De plus yBH est significtivement différente de yAL. Pour toutes les autres combinaisonq de modalités des deux facteurs, on ne peut pas considérer leurs moyennes comme significativement différentes. Ainsi l'effet des interacions des facteurs passe par les combinaisons explicitées ici.


8. Du fait des interactions, on peut comparer les modalités de __tension__ conditionnellement à celles de __wool__. Que font les fonctions suivantes? Pourquoi? Interpéter.
1.warpbreaks.wool=split(warpbreaks,wool)
2.lbreaksA.aov=aov(log(breaks)~tension,data=warpbreaks.wool$A)
3.lbreaksA.HSD <-TukeyHSD(lbreaksA.aov)

```{r}
warpbreaks.wool=split(donnees,donnees$wool);warpbreaks.wool
```

Cette commande permet de séparer le dataframe des données suivant les modalités du facteur choisi. Ici le facteur choisi étant __wool__, le dataframe a été séparé en 2. Un dataframe ne contenant que les enregistrements ayant pour modalité A (wool) mais toutes les autres modalités de __tension__. Un deuxième dataframe qui lui contient tous les enregistrements ayant B comme modalité.
Cette commande est très utile car elle va permettre de réaliser une anova à un facteur (le facteur __tension__ ici) en fixant une modalité du deuxième facteur (wool). On va donc pouvoir quantifier les effets principaux de chaque facteur conditionellement à la modalité fixée de l'autre.


```{r}
lbreaksA.aov=aov(log(breaks)~tension,data=warpbreaks.wool$A);
summary(lbreaksA.aov)
```

Cette commande réalise l'analyse de variance à un facteur (tension) en ne prenant que les enregistrements ayant A comme modalité pour __wool__. On peut alors interpréter les résultats conditionnellment à A.
Le résumé de l'anova nous indique qu'on rejette l'hypothèse nulle d'égalité des moyennes des modalités de __tension__, conditionnellement à A. Le facteur __tension__|wool=A a donc un effet sur la variable __breaks__. Nous allons maintenant regarder quelles moyennes sont significativement différentes.


```{r}
lbreaksA.HSD=TukeyHSD(lbreaksA.aov);lbreaksA.HSD
plot(lbreaksA.HSD)
```

On voit donc grâce à cette commande que yL est significativement différente de yM et yH mais que yM et yH ne peuvent pas être considérées comme significativement différentes, toujours conditionnellement à wool=A.

__Interprétation__: On remarque tout d'abord que ce graphique ne correspond plus du tout au graphique de la question 6 où seules yH et yL étaient significativement différentes. C'est normal, car on prend ici en compte les interactions des facteurs.
Ce graphique confirme ce qui a été dit à la question précédente: le facteur __tension__ a donc un effet significatif sur la variable __breaks__ à travers ces différences de moyennes, conditionnellement à wool=A.

On peut donc prédire la réaction d'une laine en terme d'usure grâce à ces résultats:
si l'on a 2 laines de type A et que l'on applique à l'une d'elle une tension H et à l'autre une tension M, alors on sait qu'il n'y aura normalement aucune différence particulière pour les mesures de __breaks__ enregistrées. En revanche si l'on applique une tension H à la première et une tension L à la seconde, on doit s'attendre à une différence dans les mesures de __breaks__ observées. Sachant que yAL est plus élevée que yAH, on doit s'attendre à une valeur de __breaks__ plus élevée pour la laine subissant la tension L que pour la laine subissant la tension H.


9. Même question que la question 8 mais avec les commandes suivantes. On procédera de préférence en utilisant le modèle complet pour optimiser l'estimation de la variance résiduelle: 
1. lbreaks.cond<-emmeans(lbreaks.aov,~tension|wool)
2. pairs(lbreaks.cond); cld(lbreaks.cond)

```{r message=FALSE}
library(emmeans)
library(multcomp)
lbreaks.aov=aov(log(breaks)~tension+wool+tension:wool,data=donnees)
lbreaks.cond=emmeans(lbreaks.aov,~tension|wool)
pairs(lbreaks.cond)
```

La commande pairs(lbreaks.cond) permet de réaliser les anova à un facteur en fixant les modalités du deuxième facteur. Elle permet donc de quantifier et d'interpréter les effets principaux de chaque facteur lorsqu'il y a des interactions significatives entre facteurs. 

On retrouve ici que pour la modalité A fixée de __wool__, les moyennes des modalités M et H sont significativement égales alors que yL!=yH et yL!=yM.

Pour la modalité B fixée de __wool__, on remarque qu'on ne rejette aucune hypothèse nulle. Les moyennes des 3 modalités L, M et H sont toutes significativement égales. Le facteur __tension__ n'a donc aucune influence sur la variable __breaks__ conditionnellement à wool=B.

Le critère utilisé ici étant le critère de Tukey.


```{r}
cld(lbreaks.cond)
```

Cette commande donne les groupes auquels appartiennent les différentes modalités d'un facteur en fonction de leur différence de moyenne (quantifié par la méthode de Tukey), comme il avait été vu dans le cours sur l'anova à un facteur avec les différentes espèces de fleurs.

Ici, conditionnellement à wool=A, l'écart de moyenne entre la modalité M et la modalité H du facteur __tension__ n'est pas assez grand pour placer la modalité M dans un groupe différent de celui de H (groupe 1 par défaut) alors que l'écart de moyenne entre la modalité M et L est suffisament grand pour placer la modalité L dans un second groupe (groupe 2).

Conditionnellement à wool=B, toutes les modalités sont plaçées dans le même groupe. En effet, par défaut la modalité H est plaçée dans le groupe 1, puis la modalité M n'ayant pas une moyenne significativement différente de celle de H, elle est aussi plaçée dans le groupe 1. Et ce, de même pour la modalité L dont la moyenne n'est pas significativement différente de celle de M.


__Conclusion__: Cette analyse de variance à 2 facteurs à mis en évidence des interactions significatives entre les 2 facteurs __wool__ et __tension__. Ainsi, pour quantifier et interpréter les effets principaux de chaque facteur, nous avons fixé tour après tour les modalités de __wool__ pour étudier les effets du facteur __tension__ sur la variable __breaks__. 

Ce qui ressort de cette analyse est que si le type de laine est A, alors on doit/peut s'attendre à une différence de réaction de la laine à l'usure suivant la tension appliquée, lorsque l'on compare deux laines de même type (A en l'occurence) et qu'on leur applique des tensions différentes. Les différences auront lieu si on applique une tension L et H ou un tension L et M mais pas lorsqu'on applique une tension H et M.

Si le type de laine est B, alors d'après cette étude, il n'y aura aucune différence de réaction de la laine à l'usure suivant les différentes tensions appliquées car l'étude n'a montré aucune différence significative de moyenne entre les modalités de __tension__|wool=B.
